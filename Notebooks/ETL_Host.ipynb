{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Libraries\n",
    "import psycopg2 as pg\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import pycountry_convert as pc\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import psycopg2.extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. set environment variable for psycog2 (for some systems)\n",
    "os.environ[\"PGGSSENCMODE\"] = \"disable\"\n",
    "\n",
    "#3. get the stored Passwords\n",
    "f=open(\"credentials.txt\", \"rt\")\n",
    "pwd=f.readline().strip()  #di   pass \n",
    "f.close()\n",
    "\n",
    "#4. test connections using the password\n",
    "# FCUL server\n",
    "#host_di = \"appserver-01.alunos.di.fc.ul.pt\"\n",
    "#db_di = \"tpd012\"\n",
    "#user_di = \"tpd012\"\n",
    "\n",
    "#conn = pg.connect(host = host_di, database = db_di, user = user_di, password = pwd)\n",
    "#conn.close()\n",
    "\n",
    "# Local server\n",
    "host = \"localhost\"\n",
    "database=\"teste\"\n",
    "user=\"postgres\"\n",
    "password=\"0000\"\n",
    "\n",
    "conn = pg.connect(host=host,database=database, user=user, password=password)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/air/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3051: DtypeWarning: Columns (61,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/listings_al.csv\")\n",
    "df_gdp = pd.read_csv('../data/GDP per capita (worldbank).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values:\n",
    "def is_nan(x):\n",
    "    return (x != x)\n",
    "\n",
    "def get_host_name(name):\n",
    "    if is_nan(name): return \"Unknown\"\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_host_membership_duration(date):\n",
    "    if is_nan(date): return \"Unknown\"\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    #date is a string with the date as YYYY-MM-DD\n",
    "    membership_time = now.year - int(date[0:4])\n",
    "    if membership_time > 10: return \"Member for more than 10 years\"\n",
    "    if membership_time > 5: return \"Member for more than 5 years\"\n",
    "    if membership_time > 2: return \"Member for more than 2 years\"\n",
    "    if membership_time >= 1: return \"Member for more than 1 year\"\n",
    "    if membership_time < 1: return \"Member for less than 1 year\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the main focus of this analysis is based on the host location, we are not interested in keeping records lacking this information. In that sense, all host records who don't have a known location will be ignored - None lines will be later removed in preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_host_country(location):\n",
    "    #location is a string with the host location -- may not have country\n",
    "    location = str(location)\n",
    "    if re.search('po.*tugal', location, re.IGNORECASE): return \"Portugal\"\n",
    "    if re.search('lisbo', location, re.IGNORECASE): return \"Portugal\"\n",
    "    if re.search('PT', location): return \"Portugal\"\n",
    "    if re.search('spain', location, re.IGNORECASE): return \"Spain\"\n",
    "    if re.search('ES', location): return \"Spain\"\n",
    "    if re.search('madrid', location, re.IGNORECASE): return \"Spain\"\n",
    "    if re.search('united kingdom', location, re.IGNORECASE): return \"United Kingdom\"\n",
    "    if re.search('UK', location): return \"United Kingdom\"\n",
    "    if re.search('GB', location): return \"United Kingdom\"\n",
    "    if re.search('ireland', location, re.IGNORECASE): return \"United Kingdom\"\n",
    "    if re.search('denmark', location, re.IGNORECASE): return \"Denmark\"\n",
    "    if re.search('netherlands', location, re.IGNORECASE): return \"Netherlands\"\n",
    "    if re.search('NL', location): return \"Netherlands\"\n",
    "    if re.search('germany', location, re.IGNORECASE): return \"Germany\"\n",
    "    if re.search('DE', location): return \"Germany\"\n",
    "    if re.search('belgium', location, re.IGNORECASE): return \"Belgium\"\n",
    "    if re.search('united states', location, re.IGNORECASE): return \"United States\"\n",
    "    if re.search('US', location): return \"United States\"\n",
    "    if re.search('canada', location, re.IGNORECASE): return \"Canada\"\n",
    "    if re.search('france', location, re.IGNORECASE): return \"France\"\n",
    "    if re.search('FR', location): return \"France\"\n",
    "    if re.search('italy', location, re.IGNORECASE): return \"Italy\"\n",
    "    if re.search('IT', location): return \"Italy\"\n",
    "    if re.search('switzerland', location, re.IGNORECASE): return \"Switzerland\"\n",
    "    if re.search('sweden', location, re.IGNORECASE): return \"Sweden\"\n",
    "    if re.search('poland', location, re.IGNORECASE): return \"Poland\"\n",
    "    if re.search('finland', location, re.IGNORECASE): return \"Finland\"\n",
    "    if re.search('serbia', location, re.IGNORECASE): return \"Serbia\"\n",
    "    if re.search('austria', location, re.IGNORECASE): return \"Austria\"\n",
    "    if re.search('iceland', location, re.IGNORECASE): return \"Iceland\"\n",
    "    if re.search('norway', location, re.IGNORECASE): return \"Norway\"\n",
    "    if re.search('china', location, re.IGNORECASE): return \"China\"\n",
    "    if re.search('angola', location, re.IGNORECASE): return \"Angola\"\n",
    "    if re.search('australia', location, re.IGNORECASE): return \"Australia\"\n",
    "    if re.search('brazil', location, re.IGNORECASE): return \"Brazil\"\n",
    "    if re.search('BR', location): return \"Brazil\"\n",
    "    if re.search('peru', location, re.IGNORECASE): return \"Peru\"\n",
    "    if re.search('sri lanka', location, re.IGNORECASE): return \"Sri Lanka\"\n",
    "    if re.search('vietnam', location, re.IGNORECASE): return \"Vietnam\"\n",
    "    if re.search('united arab emirates', location, re.IGNORECASE): return \"United Arab Emirates\"\n",
    "    if re.search('south africa', location, re.IGNORECASE): return \"South Africa\"\n",
    "    if re.search('qatar', location, re.IGNORECASE): return \"Qatar\"\n",
    "    if re.search('japan', location, re.IGNORECASE): return \"Japan\"\n",
    "    if re.search('turkey', location, re.IGNORECASE): return \"Turkey\"\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to keep in mind is that this method of identificating the host country is not the best, since it is not very generalizable to new data. In order for this method to work safely for all new data, an extended 'database' of countries would be needed. Here we made an effort to cover the most common countries in the dataset, but did not extend it much in order to preserve performance.\n",
    "\n",
    "One alternative that we pursued was using the `pycountry` library, but since it ws very inefficient (for each record it would go through all countries in the library) we decided that for this purpose the purpose of this work the method above could be satisfatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_host_continent(country):\n",
    "    if country == None: return None\n",
    "    \n",
    "    continents_dic = {\n",
    "    'EU': 'Europe',\n",
    "    'NA': 'North America',\n",
    "    'SA': 'South America', \n",
    "    'AS': 'Asia',\n",
    "    'OC': 'Australia',\n",
    "    'AF': 'Africa',\n",
    "    }\n",
    "    \n",
    "    # Acquire the country code\n",
    "    country_code = pc.country_name_to_country_alpha2(country, cn_name_format=\"default\")\n",
    "    # Convert country code to continent code; use dictionary to return continent name\n",
    "    continent_name = pc.country_alpha2_to_continent_code(country_code)\n",
    "    \n",
    "    return continents_dic[continent_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_host_country_gdp(country):\n",
    "    if country == None: return None\n",
    "    \n",
    "    # Always get latest (most updated) gdp available in the gdp dataset - last column\n",
    "    # The level of detail required here is not very high, since we will use bins\n",
    "    # to characterize the countries' wealth\n",
    "    dict_gdp = pd.Series(df_gdp.iloc[:,-1].values, index=df_gdp['Country Name']).to_dict()\n",
    "    \n",
    "    if country not in dict_gdp.keys(): return \"Unknown\"\n",
    "    \n",
    "    gdp = dict_gdp[country]\n",
    "    if gdp <= 20000  : return \"Below 20k\"\n",
    "    if gdp <= 35000  : return \"20k - 35k\"\n",
    "    if gdp <= 50000  : return \"35k - 50k\"\n",
    "    if gdp > 50000 : return \"Above 50k\"\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_host_response_time(response_time):\n",
    "    if is_nan(response_time): return \"Unknown\"\n",
    "    return response_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_host_is_superhost(is_superhost):\n",
    "    if is_superhost == 't': return \"Superhost\"\n",
    "    if is_superhost == 'f': return \"Not Superhost\"\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_host_identity_verified(identity):\n",
    "    if identity == 't': return \"Verified\"\n",
    "    if identity == 'f': return \"Unverified\"\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create clean dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_id = [i for i in df['id']]\n",
    "names = [n for n in df['host_name']]\n",
    "membership_duration = [get_host_membership_duration(d) for d in df['host_since']]\n",
    "country = [get_host_country(l) for l in df['host_location']]\n",
    "continent = [get_host_continent(c) for c in country]\n",
    "gdp = [get_host_country_gdp(c) for c in country]\n",
    "response_time = [get_host_response_time(t) for t in df['host_response_time']]\n",
    "superhost = [get_host_is_superhost(b) for b in df['host_is_superhost']]\n",
    "identity_verified = [get_host_identity_verified(i) for i in df['host_identity_verified']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17168, 9)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['listing_id','host_name', 'membership_duration','host_country', 'host_continent', \n",
    "           'host_country_gdp', 'host_response_time', 'host_is_superhost', 'host_is_verified']\n",
    "df_host_dimension = pd.DataFrame(np.stack((listing_id, names, membership_duration, country, \n",
    "                                           continent, gdp, response_time, superhost, \n",
    "                                           identity_verified),axis=-1), columns = columns)\n",
    "df_host_dimension.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_null_rows(df,columns):\n",
    "    \"\"\"Removes all records with any empty cells from input DataFrame\"\"\"\n",
    "    processed_df = df[columns].copy()\n",
    "    total_rows = processed_df.shape[0]\n",
    "    delete_rows = []\n",
    "    \n",
    "    if processed_df.isnull().values.any(): # if there are any null values in DataFrame, process DataFrame\n",
    "        for index, row in enumerate(processed_df.itertuples(), start = 0):\n",
    "            if (pd.Series(row).isnull().values.any()): # if row has any null value\n",
    "                delete_rows.append(index) # add row index to delete list\n",
    "    \n",
    "    processed_df.drop(df.index[delete_rows], inplace = True) # delete rows fr\n",
    "    processed_df = processed_df.reset_index().drop('index', axis = 1)\n",
    "    print('DataFrame contains {} rows. Deleted {} rows ({}% of total rows)'.format(processed_df.shape[0], len(delete_rows), round(len(delete_rows)*100/total_rows, 2)))\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame contains 17005 rows. Deleted 163 rows (0.95% of total rows)\n"
     ]
    }
   ],
   "source": [
    "df_host_dimension = delete_null_rows(df_host_dimension, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add primary key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pks = [i for i in range(1,df_host_dimension.shape[0]+1)]\n",
    "df_host_dimension.insert(0, \"host_id\", pks, True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicates, mapping the each listing to these new FK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['host_id','host_name', 'membership_duration','host_country', 'host_continent', \n",
    "           'host_country_gdp', 'host_response_time', 'host_is_superhost', 'host_is_verified']\n",
    "\n",
    "host_dimension_processed = df_host_dimension[columns].drop_duplicates().copy()\n",
    "host_dimension_processed = host_dimension_processed.reset_index().drop('index', axis = 1)\n",
    "host_dimension_processed.index += 1\n",
    "\n",
    "host_dimension_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributing dimension keys to facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match fact IDs with FKs in dimension\n",
    "FK = []\n",
    "for i, row in enumerate(df_host_dimension.itertuples(), start = 1):\n",
    "    row = list(row)\n",
    "    for j, dim_row in enumerate(host_dimension_processed.itertuples(), start = 1):\n",
    "        dim_row = list(dim_row)\n",
    "        if (row[2:] == dim_row[1:]): # if fact attributes are equal to dimension record attributes\n",
    "            FK.append(j)\n",
    "            break # leaves nested loop if match is found  \n",
    "len(FK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mapping = pd.DataFrame({})\n",
    "df_mapping['ID'] = list(df_host_dimension['listing_id'].copy())\n",
    "df_mapping['host_id'] = FK\n",
    "df_mapping.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Host dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_table = \"\"\"\n",
    "DROP TABLE IF EXISTS Host;\n",
    "\"\"\"\n",
    "\n",
    "create_table = \"\"\"\n",
    "CREATE TABLE Host (\n",
    "    HOST_ID SERIAL PRIMARY KEY NOT NULL,\n",
    "    HOST_NAME VARCHAR(40) NOT NULL,\n",
    "    MEMBERSHIP_DURATION VARCHAR(40) CHECK (MEMBERSHIP_DURATION in ('Member for more than 10 years','Member for more than 5 years','Member for more than 2 years','Member for more than 1 year','Member for less than 1 year', 'Unknown')) NOT NULL,\n",
    "    HOST_COUNTRY VARCHAR(20) NOT NULL,\n",
    "    HOST_CONTINENT VARCHAR(20) CHECK (HOST_CONTINENT in ('Europe','North America','South America','Asia','Australia','Africa')) NOT NULL,\n",
    "    HOST_COUNTRY_GDP VARCHAR(20) CHECK (HOST_COUNTRY_GDP in ('Below 20k','20k - 35k','35k - 50k','Above 50k')) NOT NULL,\n",
    "    HOST_RESPONSE_TIME VARCHAR(20) CHECK (HOST_RESPONSE_TIME in ('within an hour','within a few hours','within a day','a few days or more','Unknown')) NOT NULL,\n",
    "    HOST_IS_SUPERHOST VARCHAR(20) CHECK (HOST_IS_SUPERHOST in ('Superhost','Not Superhost')) NOT NULL,\n",
    "    HOST_IS_VERIFIED VARCHAR(20) CHECK (HOST_IS_VERIFIED in ('Verified','Unverified')) NOT NULL\n",
    "    )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excuteSingleSQLstatement(sql, host, database, user, password):\n",
    "    conn = pg.connect(host=host,database=database, user=user, password=password)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql)\n",
    "    cur.close()\n",
    "    conn.commit()\n",
    "    conn.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "excuteSingleSQLstatement(delete_table, host, database, user, password)\n",
    "excuteSingleSQLstatement(create_table, host, database, user, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for bulk insert\n",
    "def insert_data(df, table_name, conn):\n",
    "    df_columns = list(df)\n",
    "    columns = \",\".join(df_columns)\n",
    "    values = \"VALUES({})\".format(\",\".join([\"%s\" for _ in df_columns])) \n",
    "    insert_stmt = \"INSERT INTO {} ({}) {}\".format(table_name,columns,values)\n",
    "    success = True\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        pg.extras.execute_batch(cursor, insert_stmt, df.values)\n",
    "        conn.commit()\n",
    "        success = True\n",
    "    except pg.DatabaseError as error:\n",
    "        success = False\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted succefully\n"
     ]
    }
   ],
   "source": [
    "if len(df_host_dimension) > 0:\n",
    "    table_name = 'Host'\n",
    "    conn = pg.connect(host=host, database=database, user=user, password=password)\n",
    "    success = insert_data(df_host_dimension,table_name, conn)\n",
    "    conn.close()\n",
    "    if success == True: print('Data inserted succefully')\n",
    "else: print('No data to insert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
