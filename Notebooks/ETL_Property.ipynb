{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import psycopg2 as pg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import psycopg2.extras\n",
    "\n",
    "# set environment variable for psycog2 (for some systems)\n",
    "os.environ[\"PGGSSENCMODE\"] = \"disable\"\n",
    "\n",
    "# get the stored passwords\n",
    "f=open(\"credentials.txt\", \"rt\")\n",
    "pwd=f.readline().strip()  #di   password\n",
    "hpwd=f.readline().strip() #home password\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# di test: WORKING\n",
    "host_di = \"appserver-01.alunos.di.fc.ul.pt\"\n",
    "db_di = \"tpd012\"\n",
    "user_di = \"tpd012\"\n",
    "\n",
    "conn = pg.connect(host = host_di,\n",
    "                  database = db_di,\n",
    "                  user = user_di,\n",
    "                  password = pwd)\n",
    "conn.close()\n",
    "\n",
    "# local test: WORKING\n",
    "#host_local = \"localhost\"\n",
    "#db_local = \"tpd012\"\n",
    "#user_local = \"postgres\"\n",
    "\n",
    "#conn = pg.connect(host = host_local,\n",
    "#                  database = db_local,\n",
    "#                  user = user_local,\n",
    "#                  password=hpwd)\n",
    "#conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_al_file_path = '../data/listings_al.csv'\n",
    "df_listings_al = pd.read_csv(listings_al_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The defined _'Property'_ dimension table in __Phase I__ is as follows:\n",
    "\n",
    "<img src=\"property_schema.png\" width=\"150\" align=\"center\"/>\n",
    "\n",
    "# __CHANGE SCHEMA__\n",
    "\n",
    "<img src=\"PropertyETL.png\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_null_rows(df,columns):\n",
    "    \"\"\"Removes all records with any empty cells from input DataFrame\"\"\"\n",
    "    processed_df = df[columns].copy()\n",
    "    total_rows = processed_df.shape[0]\n",
    "    delete_rows = []\n",
    "    \n",
    "    if processed_df.isnull().values.any(): # if there are any null values in DataFrame, process DataFrame\n",
    "        for index, row in enumerate(processed_df.itertuples(), start = 0):\n",
    "            if (pd.Series(row).isnull().values.any()): # if row has any null value\n",
    "                delete_rows.append(index) # add row index to delete list\n",
    "    \n",
    "    processed_df.drop(df.index[delete_rows], inplace = True) # delete rows fr\n",
    "    processed_df = processed_df.reset_index().drop('index', axis = 1)\n",
    "    print('DataFrame contains {} rows. Deleted {} rows ({}% of total rows)'.format(processed_df.shape[0], len(delete_rows), round(len(delete_rows)*100/total_rows, 2)))\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_columns = ['id',\n",
    "                    'property_type',\n",
    "                    'room_type',\n",
    "                    'accommodates',\n",
    "                    'bathrooms',\n",
    "                    'bedrooms',\n",
    "                    'beds',\n",
    "                    'bed_type']\n",
    "\n",
    "df_property = delete_null_rows(df_listings_al,property_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From `df_property`, we create `df_conv_fact`, which will be the table containing a record for each fact ID converted to the dimension format. `property_dimension` will be the _de facto_ property dimension from which we can correspond each fact ID record to the appropriate dimension foreign key according to its set of attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _'property_type_category'_\n",
    "\n",
    "We start by creating _'property_type_category'_, a set of four categories from _'property_type'_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_property_type_category(value):\n",
    "# change 'property_type' to four categories, exclude exceptions\n",
    "    if value in [\"Apartment\", \"Serviced apartment\", \"Aparthotel\",\"Loft\"]:\n",
    "        return 'Apartment'\n",
    "    if value in [\"House\",\"Townhouse\",\"Villa\",\"Dome house\",\"Vacation home\",\"Lighthouse\",\"Casa particular (Cuba)\",\"Tiny house\",\"Farm stay\",\"Cottage\"]:\n",
    "        return 'House'\n",
    "    if value in [\"Guesthouse\",\"Guest suite\"]:\n",
    "        return 'Guesthouse'\n",
    "    if value in [\"Hostel\",\"Bed and breakfast\",\"Boutique hotel\",\"Hotel\"]:\n",
    "        return 'Hotel/Hostel'\n",
    "    return None # for the case of missing or invalid values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _'room_type'_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This attribute is already defined in satisfactory categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _'accommodates'_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accommodates(value):\n",
    "# change 'property_type' to four categories, exclude exceptions\n",
    "    if value in [1,2]: return 'Up to 2 guests'\n",
    "    if value in [3,4]: return 'Up to 4 guests'\n",
    "    if value in [5,6]: return 'Up to 6 guests'\n",
    "    return 'Up to 7 guests or more' # no missing values in this column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _'bathrooms'_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bathrooms(value):\n",
    "# change 'bathrooms' to five categories, exclude exceptions\n",
    "    if value < 0.5: return 'No bathrooms'\n",
    "    if value < 1.5: return '1 bathroom'\n",
    "    if value < 2.5: return '2 bathrooms'\n",
    "    if value < 3.5: return '3 bathrooms'\n",
    "    if value >= 3.5: return '4+ bathrooms'\n",
    "    return None # for the case of missing or invalid values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _'bedrooms'_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bedrooms(value):\n",
    "# change 'bedrooms' to five categories, exclude exceptions\n",
    "    if value == 0: return 'T0'\n",
    "    if value == 1: return 'T1'\n",
    "    if value == 2: return 'T2'\n",
    "    if value == 3: return 'T3'\n",
    "    if value >= 4: return 'T4+'\n",
    "    return None # for the case of missing or invalid values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _'beds'_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beds(value):\n",
    "# change 'beds' to five categories, exclude exceptions\n",
    "    if value == 0: return 'No beds'\n",
    "    if value == 1: return '1 bed'\n",
    "    if value == 2: return '2 beds'\n",
    "    if value == 3: return '3 beds'\n",
    "    if value >= 4: return '4+ beds'\n",
    "    return None # for the case of missing or invalid values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_facts_property(df_non_null_facts):\n",
    "    \"\"\"Performs preprocessing in facts to a Property dimension format\"\"\"\n",
    "    dimension = {}\n",
    "\n",
    "    dimension['ID'] = [value for value in df_property['id']]\n",
    "    dimension['property_type_category'] = [get_property_type_category(value) for value in df_property['property_type']]\n",
    "    dimension['property_type'] = [value for value in df_property['property_type']]\n",
    "    dimension['room_type'] = [value for value in df_property['room_type']]\n",
    "    dimension['accommodates'] = [get_accommodates(value) for value in df_property['accommodates']]\n",
    "    dimension['bathrooms'] = [get_bathrooms(value) for value in df_property['bathrooms']]\n",
    "    dimension['bedrooms'] = [get_bedrooms(value) for value in df_property['bedrooms']]\n",
    "    dimension['beds'] = [get_beds(value) for value in df_property['beds']]\n",
    "    dimension['bed_type'] = [value for value in df_property['bed_type']]\n",
    "\n",
    "    df_conv_facts = pd.DataFrame(dimension)\n",
    "    df_conv_facts.index += 1\n",
    "    df_conv_facts = delete_null_rows(df_conv_facts,df_conv_facts.columns)\n",
    "    \n",
    "    return df_conv_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conv_facts = convert_facts_property(df_property)\n",
    "\n",
    "df_conv_facts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Creating the dimension table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Property (\n",
    "    PROPERTY_ID SERIAL PRIMARY KEY NOT NULL,\n",
    "    PROPERTY_TYPE_CATEGORY VARCHAR(30) CHECK (PROPERTY_TYPE_CATEGORY in ('Apartment', 'Guesthouse', 'House', 'Hotel/Hostel')) NOT NULL,\n",
    "    PROPERTY_TYPE VARCHAR(30) CHECK (PROPERTY_TYPE in ('Apartment','Serviced apartment','Aparthotel','Loft','House','Townhouse','Villa','Dome house','Vacation home','Lighthouse','Casa particular (Cuba)','Tiny house','Farm stay','Cottage','Guesthouse','Guest suite','Hostel','Bed and breakfast','Boutique hotel','Hotel')) NOT NULL,\n",
    "    ROOM_TYPE VARCHAR(30) CHECK (ROOM_TYPE in ('Entire home/apt', 'Private room', 'Hotel room', 'Shared room')) NOT NULL,\n",
    "    ACCOMMODATES VARCHAR(30) CHECK (ACCOMMODATES in ('Up to 2 guests','Up to 4 guests','Up to 6 guests','Up to 7 guests or more')) NOT NULL,\n",
    "    BATHROOMS VARCHAR(30) CHECK (BATHROOMS in ('No bathrooms','1 bathroom','2 bathrooms','3 bathrooms','4+ bathrooms')) NOT NULL,\n",
    "    BEDROOMS VARCHAR(10) CHECK (BEDROOMS in ('T0','T1','T2','T3','T4+')) NOT NULL,\n",
    "    BEDS VARCHAR(10) CHECK (BEDS in ('No beds','1 bed','2 beds','3 beds','4+ beds')) NOT NULL,\n",
    "    BED_TYPE VARCHAR(30) CHECK (BED_TYPE in ('Real Bed', 'Pull-out Sofa', 'Futon', 'Couch', 'Airbed')) NOT NULL\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `create_table` command contains the integrity constraints essential for modelling the dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def run_sql_command(sql, host, database, user, password):\n",
    "    \"\"\"Executes a single SQL statement from a string variable and the database credentials\"\"\"\n",
    "    conn = pg.connect(host = host,\n",
    "                      database = database,\n",
    "                      user = user,\n",
    "                      password = password)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql)\n",
    "    cur.close()\n",
    "    conn.commit()\n",
    "    conn.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating table from scratch\n",
    "run_sql_command(create_table, host_di, db_di, user_di, pwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimension table is created empty, to be populated later with incoming data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1. Adding new data to dimension table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_property_dimension(df_conv_facts,columns):\n",
    "    \"\"\"Creates a Property dimension table from a converted facts DataFrame\"\"\"\n",
    "    property_dimension = df_conv_facts[columns].drop_duplicates().copy()\n",
    "    property_dimension = property_dimension.reset_index().drop('index', axis = 1)\n",
    "    property_dimension.index += 1\n",
    "\n",
    "    return property_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_dimension_new = create_property_dimension(df_conv_facts,list(df_conv_facts.columns[1:]))\n",
    "\n",
    "property_dimension_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to query table and convert it to pandas dataframe\n",
    "def query_table(conn, table_name):\n",
    "    \"\"\"Returns DataFrame with queried database table\"\"\"\n",
    "    sql = \"select * from {};\".format(table_name)\n",
    "    #return dataframe\n",
    "    return pd.read_sql_query(sql, conn)\n",
    "\n",
    "# for this function to run, the dataframes must have the same columns, in the same order\n",
    "def get_data_to_insert(df_etl, df_sql):\n",
    "    \"\"\"Returns data valid for insertion in dimension from a new ETL-processed DataFrame\"\"\"\n",
    "    return df_etl[~df_etl.isin(df_sql)].dropna(how = 'all') # checks which rows are not yet in the dimension\n",
    "\n",
    "# function for bulk insert\n",
    "def insert_data(df, table_name, conn):\n",
    "    \"\"\"Inserts selected data into dimension table in database\"\"\"\n",
    "    df_columns = list(df)\n",
    "    columns = \",\".join(df_columns)\n",
    "    values = \"VALUES({})\".format(\",\".join([\"%s\" for _ in df_columns])) \n",
    "    insert_stmt = \"INSERT INTO {} ({}) {}\".format(table_name,columns,values)\n",
    "    success = True\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        psycopg2.extras.execute_batch(cursor, insert_stmt, df.values)\n",
    "        conn.commit()\n",
    "        success = True\n",
    "    except pg.DatabaseError as error:\n",
    "        success = False\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve Property dimension table\n",
    "conn = pg.connect(host = host_di,\n",
    "                        database = db_di,\n",
    "                        user = user_di,\n",
    "                        password = pwd)\n",
    "\n",
    "property_dimension_old = query_table(conn, 'property')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "property_dimension_old.set_index('property_id', inplace = True)\n",
    "\n",
    "property_dimension_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks which rows from new data will be inserted into database dimension table\n",
    "def get_data_to_insert(df1, df2, columns):\n",
    "    \"\"\"Checks if rows in df1 are already present in df2\"\"\"\n",
    "    return df1[~df1[columns].apply(tuple,1).isin(df2[columns].apply(tuple,1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compares rows (excluding unique IDs) of new data and database dimension\n",
    "dimension_insert = get_data_to_insert(property_dimension_new,property_dimension_old,property_dimension_new.columns[1:])\n",
    "dimension_insert.index += property_dimension_old.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uploading new data to dimension in database\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"postgres://{user}:{password}@{host}:5432/{database}\".format(user = user_di,\n",
    "                                                                                    password = pwd,\n",
    "                                                                                    host = host_di,\n",
    "                                                                                    database = db_di))\n",
    "dimension_insert.to_sql('property',\n",
    "                          con = engine,\n",
    "                          if_exists = 'append',\n",
    "                          index = True,\n",
    "                          index_label = 'property_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Attributing dimension keys to facts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having our dimension DataFrame `property_dimension` ready, we can now use our converted listings table, `df_conv_facts` (which contains Property dimension attributes for all valid facts), to assign each fact its corresponding Property dimension foreign key.\n",
    "\n",
    "<img src=\"PropertyETL2.png\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve updated Property dimension table for mapping\n",
    "conn = pg.connect(host = host_di,\n",
    "                        database = db_di,\n",
    "                        user = user_di,\n",
    "                        password = pwd)\n",
    "\n",
    "property_dimension_updated = query_table(conn, 'property')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "property_dimension_updated.set_index('property_id', inplace = True)\n",
    "property_dimension_updated.reset_index(inplace = True)\n",
    "\n",
    "property_dimension_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_mapping(df1, df2, pk1, pk2):\n",
    "    # This function merges two dataframes, and creates a map linking their keys\n",
    "    df_merged = df1.merge(df2, how='outer')\n",
    "    df_map = pd.DataFrame()\n",
    "    df_map[pk1]= df_merged[pk1]\n",
    "    df_map[pk2]= df_merged[pk2]\n",
    "    \n",
    "    df_map = delete_null_rows(df_map,df_map.columns)\n",
    "    \n",
    "    return df_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match fact IDs with FKs in dimension\n",
    "df_mapping = key_mapping(df_conv_facts, property_dimension_updated, 'ID', 'property_id')\n",
    "df_mapping.to_csv('df_listings_property.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table can then be merged with all other corresponding tables for the remaining dimensions to produce each fact record in the facts table. It will be used both in the _Listings_ and _Availability_ facts tables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
