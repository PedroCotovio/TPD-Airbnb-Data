{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tecnologias de Processamento de dados - 2019/2020\n",
    "\n",
    "## Phase II - Group 12\n",
    "\n",
    "\n",
    "|   Student      | Student ID |  Contribution in hours |\n",
    "|----------------|------------|----------------|\n",
    "| Beatriz Lima   |    49377   |   |\n",
    "| David Almeida  |    54120   |   |\n",
    "|Jo√£o Castanheira|    55052   |   |\n",
    "| Pedro Cotovio  |    55053   |   |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main datasets used in this warehouse are:\n",
    "\n",
    "- http://insideairbnb.com/get-the-data.html for Lisbon, Portugal. - listings.csv\n",
    "- https://dadosabertos.turismodeportugal.pt/datasets/alojamento-local) - Alojamento_Local.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_file_path = '../data/airbnb/listings.csv'\n",
    "al_file_path = '../data/Alojamento_Local.csv'\n",
    "df_al = pd.read_csv(al_file_path)\n",
    "df_listings = pd.read_csv(listings_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Merge _df_listings_ with _alojamento_local.csv_\n",
    "\n",
    "In order to enrich the main dataset, we can cross it with the dataset from Registo Nacional de Alojamento Local (RNAL) to obtain further information regarding each listing's property, as well as refine already available data, particularly in the case of location data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def intTryParse(value):\n",
    "    \"\"\"Tries to parse string to an integer\"\"\"\n",
    "    try:\n",
    "        a = int(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joao_\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# get only listings where \n",
    "df_listings_with_license = df_listings[(~df_listings['license'].isnull()) #'license' is not null\n",
    "                                        & (df_listings['license'] != 'Exempt')] # && != 'Exempt'\n",
    "\n",
    "# string replace\n",
    "df_listings_with_license['NrRNAL'] = [s.replace('/AL','').replace('.','') # remove '/AL' and '.' from code\n",
    "                                      for s in df_listings_with_license['license']]\n",
    "\n",
    "# get only records where license nr can be converted to int \n",
    "df_listings_with_license = df_listings_with_license[[intTryParse(s) # if code can be converted to int\n",
    "                                                     for s in df_listings_with_license['NrRNAL']]] # keep it\n",
    "\n",
    "# convert NrRNAL to int before merge the two dataframes\n",
    "df_listings_with_license['NrRNAL'] = df_listings_with_license['NrRNAL'].astype(np.int64) # convert code to int\n",
    "\n",
    "# inner join two dataframes\n",
    "df_listings_al = pd.merge(df_listings_with_license, df_al, how='inner', on='NrRNAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Save the intersection of the two files to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 17168\n"
     ]
    }
   ],
   "source": [
    "listings_al_file_path = '../data/listings_al.csv'\n",
    "df_listings_al.to_csv(listings_al_file_path,index=False)\n",
    "print('Dataset size: {}'.format(len(df_listings_al)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dimensions and facts tables of the data warehouse\n",
    "\n",
    "+ Define and model them in SQL\n",
    "+ Identify hierarchies and fact granularity\n",
    "+ Create the dimensions and facts tables in the DBMS (postgreSQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General schema\n",
    "\n",
    "![Star schema](../images/schema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define an ETL workflow\n",
    "\n",
    "+ Identify all data sources for all dimensions. Add URL links to all data that should be available. If not public data, point to dropbox files, Google drive, or whatever\n",
    "+ For each dimension show the code used for modeling, filtering and inserting data\n",
    "+ Describe the process for inserting facts data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ETL workflow is defined in separate notebooks for each dimension:\n",
    "\n",
    " - ETL_Property.ipynb\n",
    " - ETL_Host.ipynb\n",
    " - ETL_Review.ipynb\n",
    " - ETL_Date.ipynb\n",
    " - ETL_Location.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Critical assessment of the work\n",
    "+ Describe potential issues with the ETL procedure used\n",
    "+ Compare your schema to the one previously defined in phase I\n",
    "+ Discuss the issues for updating the data warehouse with novel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mention that dimensions might have unnecessary rows! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe facts loading:\n",
    "* Merge every mapping\n",
    "* Merge with one fact\n",
    "* Merge Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_listing_price(listing_id):\n",
    "    return int(df_listings_al[df_listings_al['id']==listing_id].price.values[0].strip().split('.')[0].replace(',','').replace('$',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the mappings between each dimension and the listing fact table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_date_path = '../processed_dt/df_listings_date.csv'\n",
    "listings_host_path = '../processed_dt/df_listings_host.csv'\n",
    "listings_property_path = '../processed_dt/df_listings_property.csv'\n",
    "listings_review_path = '../processed_dt/df_listings_review.csv'\n",
    "listings_location_path = '../processed_dt/location_fk.csv'\n",
    "\n",
    "df_listings_date = pd.read_csv(listings_date_path)[['listing_id','date_id']]\n",
    "df_listings_host = pd.read_csv(listings_host_path)[['listing_id','host_id']]\n",
    "df_listings_property = pd.read_csv(listings_property_path).rename(columns={'ID':'listing_id','Property':'property_id'})[['listing_id','property_id']]\n",
    "df_listings_review = pd.read_csv(listings_review_path)[['listing_id','review_id']]\n",
    "df_listings_location = pd.read_csv(listings_location_path).rename(columns={'fk':'location_id','listings_id':'listing_id'})[['listing_id','location_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inner join all dataframes, by listing_id\n",
    "dfs = [df_listings_date, df_listings_host, df_listings_property, df_listings_review, df_listings_location]\n",
    "df_listings_facts = reduce(lambda  left,right: pd.merge(left,right,on=['listing_id'], how='inner'), dfs)\n",
    "#get the fact metric\n",
    "df_listings_facts['price_per_night'] = [get_listing_price(i) for i in df_listings_facts['listing_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>host_id</th>\n",
       "      <th>property_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>price_per_night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25659</td>\n",
       "      <td>13092017</td>\n",
       "      <td>107347</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1194</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29248</td>\n",
       "      <td>15012016</td>\n",
       "      <td>125768</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>537</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29396</td>\n",
       "      <td>12052016</td>\n",
       "      <td>126415</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1745</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29720</td>\n",
       "      <td>31082017</td>\n",
       "      <td>128075</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1592</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29915</td>\n",
       "      <td>16102018</td>\n",
       "      <td>128890</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>480</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12049</th>\n",
       "      <td>41079317</td>\n",
       "      <td>22042016</td>\n",
       "      <td>316386247</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1828</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12050</th>\n",
       "      <td>41251727</td>\n",
       "      <td>1012020</td>\n",
       "      <td>303598743</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>725</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12051</th>\n",
       "      <td>41397838</td>\n",
       "      <td>8032017</td>\n",
       "      <td>318669472</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1669</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12052</th>\n",
       "      <td>41403386</td>\n",
       "      <td>3122019</td>\n",
       "      <td>325646937</td>\n",
       "      <td>1023</td>\n",
       "      <td>3</td>\n",
       "      <td>1293</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12053</th>\n",
       "      <td>41429288</td>\n",
       "      <td>25092018</td>\n",
       "      <td>317037161</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>969</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12054 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       listing_id   date_id    host_id  property_id  review_id  location_id  \\\n",
       "0           25659  13092017     107347            1          1         1194   \n",
       "1           29248  15012016     125768            2          2          537   \n",
       "2           29396  12052016     126415            1          1         1745   \n",
       "3           29720  31082017     128075            3          1         1592   \n",
       "4           29915  16102018     128890            5          3          480   \n",
       "...           ...       ...        ...          ...        ...          ...   \n",
       "12049    41079317  22042016  316386247            9          9         1828   \n",
       "12050    41251727   1012020  303598743            7         14          725   \n",
       "12051    41397838   8032017  318669472            2          2         1669   \n",
       "12052    41403386   3122019  325646937         1023          3         1293   \n",
       "12053    41429288  25092018  317037161           39         14          969   \n",
       "\n",
       "       price_per_night  \n",
       "0                 60.0  \n",
       "1                 60.0  \n",
       "2                 60.0  \n",
       "3               1000.0  \n",
       "4                 45.0  \n",
       "...                ...  \n",
       "12049             38.0  \n",
       "12050             40.0  \n",
       "12051             50.0  \n",
       "12052             80.0  \n",
       "12053             35.0  \n",
       "\n",
       "[12054 rows x 7 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_listings_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>date_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41791859</td>\n",
       "      <td>28012020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41791859</td>\n",
       "      <td>29012020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41791859</td>\n",
       "      <td>30012020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41791859</td>\n",
       "      <td>31012020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41791859</td>\n",
       "      <td>1022020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id   date_id\n",
       "0    41791859  28012020\n",
       "1    41791859  29012020\n",
       "2    41791859  30012020\n",
       "3    41791859  31012020\n",
       "4    41791859   1022020"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_availability_date = pd.read_csv('../processed_dt/df_availability_date.csv')[['listing_id','date_id']]\n",
    "df_availability_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, False,  True,  True,  True,  True, False,\n",
       "        True,  True,  True, False, False,  True,  True, False, False,\n",
       "       False,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False,  True, False,  True,  True, False,  True,  True,  True,\n",
       "        True,  True, False, False, False, False, False,  True,  True,\n",
       "       False, False,  True, False, False,  True, False, False, False,\n",
       "       False, False])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isin(np.unique(df_availability_date.listing_id.values),df_listings_facts['listing_id'].values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
