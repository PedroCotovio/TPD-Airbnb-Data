{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tecnologias de Processamento de dados - 2019/2020\n",
    "\n",
    "## Phase II - Group 12\n",
    "\n",
    "\n",
    "|   Student      | Student ID |  Contribution in hours |\n",
    "|----------------|------------|----------------|\n",
    "| Beatriz Lima   |    49377   |   |\n",
    "| David Almeida  |    54120   |   |\n",
    "|Jo√£o Castanheira|    55052   |   |\n",
    "| Pedro Cotovio  |    55053   |   |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "import psycopg2 as pg\n",
    "import psycopg2.extras\n",
    "import pandas.io.sql as sqlio\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main datasets used in this warehouse are:\n",
    "\n",
    "- http://insideairbnb.com/get-the-data.html for Lisbon, Portugal. - listings.csv\n",
    "- https://dadosabertos.turismodeportugal.pt/datasets/alojamento-local) - Alojamento_Local.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joao_\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (61,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "listings_file_path = '../data/airbnb/listings.csv'\n",
    "al_file_path = '../data/Alojamento_Local.csv'\n",
    "df_al = pd.read_csv(al_file_path)\n",
    "df_listings = pd.read_csv(listings_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Merge _df_listings_ with _alojamento_local.csv_\n",
    "\n",
    "In order to enrich the main dataset, we can cross it with the dataset from Registo Nacional de Alojamento Local (RNAL) to obtain further information regarding each listing's property, as well as refine already available data, particularly in the case of location data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def intTryParse(value):\n",
    "    \"\"\"Tries to parse string to an integer\"\"\"\n",
    "    try:\n",
    "        a = int(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joao_\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# get only listings where \n",
    "df_listings_with_license = df_listings[(~df_listings['license'].isnull()) #'license' is not null\n",
    "                                        & (df_listings['license'] != 'Exempt')] # && != 'Exempt'\n",
    "\n",
    "# string replace\n",
    "df_listings_with_license['NrRNAL'] = [s.replace('/AL','').replace('.','') # remove '/AL' and '.' from code\n",
    "                                      for s in df_listings_with_license['license']]\n",
    "\n",
    "# get only records where license nr can be converted to int \n",
    "df_listings_with_license = df_listings_with_license[[intTryParse(s) # if code can be converted to int\n",
    "                                                     for s in df_listings_with_license['NrRNAL']]] # keep it\n",
    "\n",
    "# convert NrRNAL to int before merge the two dataframes\n",
    "df_listings_with_license['NrRNAL'] = df_listings_with_license['NrRNAL'].astype(np.int64) # convert code to int\n",
    "\n",
    "# inner join two dataframes\n",
    "df_listings_al = pd.merge(df_listings_with_license, df_al, how='inner', on='NrRNAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Save the intersection of the two files to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 17168\n"
     ]
    }
   ],
   "source": [
    "listings_al_file_path = '../data/listings_al.csv'\n",
    "df_listings_al.to_csv(listings_al_file_path,index=False)\n",
    "print('Dataset size: {}'.format(len(df_listings_al)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dimensions and facts tables of the data warehouse\n",
    "\n",
    "+ Define and model them in SQL\n",
    "+ Identify hierarchies and fact granularity\n",
    "+ Create the dimensions and facts tables in the DBMS (postgreSQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General schema\n",
    "\n",
    "![Star schema](../images/Schema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define an ETL workflow\n",
    "\n",
    "+ Identify all data sources for all dimensions. Add URL links to all data that should be available. If not public data, point to dropbox files, Google drive, or whatever\n",
    "+ For each dimension show the code used for modeling, filtering and inserting data\n",
    "+ Describe the process for inserting facts data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ETL workflow is defined in separate notebooks for each dimension:\n",
    "\n",
    " - ETL_Property.ipynb\n",
    " - ETL_Host.ipynb\n",
    " - ETL_Review.ipynb\n",
    " - ETL_Date.ipynb\n",
    " - ETL_Location.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Process and insert facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_connection import dbconnection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_listing_price(listing_id):\n",
    "    return int(df_listings_al[df_listings_al['id']==listing_id].price.values[0].strip().split('.')[0].replace(',','').replace('$',''))\n",
    "\n",
    "# function to query table and convert it to pandas dataframe\n",
    "def query_table(conn, table_name):\n",
    "    \"\"\"Returns DataFrame with queried database table\"\"\"\n",
    "    sql = \"select * from {};\".format(table_name)\n",
    "    #return dataframe\n",
    "    return sqlio.read_sql_query(sql, conn)\n",
    "\n",
    "# for this function to run, the dataframes must have the same columns, in the same order\n",
    "def get_data_to_insert(df_etl, df_sql,pk):\n",
    "    \"\"\"Returns data valid for insertion in dimension from a new ETL-processed DataFrame\"\"\"\n",
    "    if isinstance(pk, list): \n",
    "        df_insert = df_etl[~df_etl[pk].apply(tuple,1).isin(df_sql[pk].apply(tuple,1))]\n",
    "        df_insert = df_insert.drop_duplicates(subset=pk)\n",
    "    else:  \n",
    "        df_insert = df_etl[-df_etl[pk].astype(int).isin(df_sql[pk].astype(int))].dropna(how = 'all')\n",
    "        df_insert = df_insert.drop_duplicates(subset=[pk])\n",
    "    return df_insert\n",
    "\n",
    "# function for bulk insert\n",
    "def insert_data(df, table_name, conn):\n",
    "    \"\"\"Inserts selected data into dimension table in database\"\"\"\n",
    "    df_columns = list(df)\n",
    "    columns = \",\".join(df_columns)\n",
    "    values = \"VALUES({})\".format(\",\".join([\"%s\" for _ in df_columns])) \n",
    "    insert_stmt = \"INSERT INTO {} ({}) {}\".format(table_name,columns,values)\n",
    "    success = True\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        psycopg2.extras.execute_batch(cursor, insert_stmt, df.values)\n",
    "        conn.commit()\n",
    "        success = True\n",
    "    except pg.DatabaseError as error:\n",
    "        success = False\n",
    "        print('error:{}'.format(error))\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "    return success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Listing Fact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the mappings between each dimension and the listing fact table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_date_path = '../processed_dt/df_listings_date.csv'\n",
    "listings_host_path = '../processed_dt/df_listings_host.csv'\n",
    "listings_property_path = '../processed_dt/df_listings_property.csv'\n",
    "listings_review_path = '../processed_dt/df_listings_review.csv'\n",
    "listings_location_path = '../processed_dt/location_fk.csv'\n",
    "\n",
    "df_listings_date = pd.read_csv(listings_date_path)[['listing_id','date_id']]\n",
    "df_listings_host = pd.read_csv(listings_host_path)[['listing_id','host_id']]\n",
    "df_listings_property = pd.read_csv(listings_property_path).rename(columns={'ID':'listing_id','Property':'property_id'})[['listing_id','property_id']]\n",
    "df_listings_review = pd.read_csv(listings_review_path)[['listing_id','review_id']]\n",
    "df_listings_location = pd.read_csv(listings_location_path).rename(columns={'fk':'location_id','listings_id':'listing_id'})[['listing_id','location_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inner join all dataframes by 'listing_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inner join all dataframes, by listing_id\n",
    "dfs = [df_listings_date, df_listings_host, df_listings_property, df_listings_review, df_listings_location]\n",
    "df_listings_facts_etl = reduce(lambda  left,right: pd.merge(left,right,on=['listing_id'], how='inner'), dfs)\n",
    "#get the fact metric\n",
    "df_listings_facts_etl['price_per_night'] = [get_listing_price(i) for i in df_listings_facts_etl['listing_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove listings where price_per_night = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings_facts_etl = df_listings_facts_etl[df_listings_facts_etl['price_per_night']>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query listings table and convert it to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>host_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>property_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>price_per_night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [listing_id, host_id, date_id, location_id, property_id, review_id, price_per_night]\n",
       "Index: []"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = psycopg2.connect(host = dbconnection.server_host,database = dbconnection.dbname, user = dbconnection.dbusername,password = dbconnection.dbpassword,sslmode=dbconnection.sslmode,gssencmode=dbconnection.gssencmode)\n",
    "df_listings_facts_sql = query_table(conn, 'listings')\n",
    "conn.close()\n",
    "df_listings_facts_sql.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get just new listings that are not in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>host_id</th>\n",
       "      <th>property_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>price_per_night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [listing_id, date_id, host_id, property_id, review_id, location_id, price_per_night]\n",
       "Index: []"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_listings_insert = get_data_to_insert(df_listings_facts_etl,df_listings_facts_sql,'listing_id')\n",
    "df_listings_insert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert listings into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(host = dbconnection.server_host,database = dbconnection.dbname, user = dbconnection.dbusername,password = dbconnection.dbpassword,sslmode=dbconnection.sslmode,gssencmode=dbconnection.gssencmode)\n",
    "df_date_sql = query_table(conn, 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/50626058/psycopg2-cant-adapt-type-numpy-int64\n",
    "from psycopg2.extensions import register_adapter, AsIs\n",
    "psycopg2.extensions.register_adapter(np.int64, psycopg2._psycopg.AsIs)\n",
    "\n",
    "if len(df_listings_insert) > 0:\n",
    "    table_name = 'listings'\n",
    "    conn = psycopg2.connect(host = dbconnection.server_host,database = dbconnection.dbname, user = dbconnection.dbusername,password = dbconnection.dbpassword,sslmode=dbconnection.sslmode,gssencmode=dbconnection.gssencmode)\n",
    "    success = insert_data(df_listings_insert,table_name, conn)\n",
    "    conn.close()\n",
    "    if success == True: print('Data inserted successfully')\n",
    "else: print('No data to insert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data in listings fact table and save it in 'df_listings_facts_sql' dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(host = dbconnection.server_host,database = dbconnection.dbname, user = dbconnection.dbusername,password = dbconnection.dbpassword,sslmode=dbconnection.sslmode,gssencmode=dbconnection.gssencmode)\n",
    "df_listings_facts_sql = query_table(conn, 'listings')\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Availability fact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will load the availability fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_pk(date):\n",
    "    \"\"\"Builds date primary key\"\"\"\n",
    "    return int(date.strftime('%d%m%Y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from calendar.csv, which contains the data to insert into the availability fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9125846, 7)\n"
     ]
    }
   ],
   "source": [
    "df_calendar = pd.read_csv('../data/airbnb/calendar.csv')\n",
    "print(df_calendar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>date</th>\n",
       "      <th>available</th>\n",
       "      <th>price</th>\n",
       "      <th>adjusted_price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41791859</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>t</td>\n",
       "      <td>$120.00</td>\n",
       "      <td>$120.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41791859</td>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>t</td>\n",
       "      <td>$120.00</td>\n",
       "      <td>$120.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41791859</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>t</td>\n",
       "      <td>$120.00</td>\n",
       "      <td>$120.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41791859</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>t</td>\n",
       "      <td>$120.00</td>\n",
       "      <td>$120.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41791859</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>t</td>\n",
       "      <td>$120.00</td>\n",
       "      <td>$120.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1125.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id        date available    price adjusted_price  minimum_nights  \\\n",
       "0    41791859  2020-01-28         t  $120.00        $120.00             7.0   \n",
       "1    41791859  2020-01-29         t  $120.00        $120.00             7.0   \n",
       "2    41791859  2020-01-30         t  $120.00        $120.00             7.0   \n",
       "3    41791859  2020-01-31         t  $120.00        $120.00             7.0   \n",
       "4    41791859  2020-02-01         t  $120.00        $120.00             7.0   \n",
       "\n",
       "   maximum_nights  \n",
       "0          1125.0  \n",
       "1          1125.0  \n",
       "2          1125.0  \n",
       "3          1125.0  \n",
       "4          1125.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_calendar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calendar file has more than 9M records, around the number of listings * 365 days per year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this project, we will just read the first k rows of the calender file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get just the records where available = 'f', which are the records that corresponds to future bookings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 3)\n"
     ]
    }
   ],
   "source": [
    "#read just the first k items\n",
    "k = 100000\n",
    "df_bookings_etl = df_calendar[df_calendar['available'] == 'f'].iloc[:k][['listing_id','date','price']]\n",
    "\n",
    "#create columns with the date primary key\n",
    "df_bookings_etl['date_id'] = [date_pk(datetime.strptime(d, \"%Y-%m-%d\")) for d in df_bookings_etl['date']]\n",
    "\n",
    "#remove date column\n",
    "df_bookings_etl = df_bookings_etl.drop(['date'], axis=1)\n",
    "\n",
    "#rename columns price\n",
    "df_bookings_etl = df_bookings_etl.rename(columns={'price':'price_per_night'})\n",
    "\n",
    "#format column to int\n",
    "df_bookings_etl['price_per_night'] = [int(i.strip().split('.')[0].replace(',','').replace('$','')) for i in df_bookings_etl['price_per_night']]\n",
    "\n",
    "#drop duplicates if exists\n",
    "df_bookings_etl = df_bookings_etl.drop_duplicates(subset=['listing_id','date_id'])\n",
    "\n",
    "print(df_bookings_etl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>price_per_night</th>\n",
       "      <th>date_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41791859</td>\n",
       "      <td>120</td>\n",
       "      <td>28012020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41791859</td>\n",
       "      <td>120</td>\n",
       "      <td>29012020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41791859</td>\n",
       "      <td>120</td>\n",
       "      <td>30012020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41791859</td>\n",
       "      <td>120</td>\n",
       "      <td>31012020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41791859</td>\n",
       "      <td>120</td>\n",
       "      <td>1022020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id  price_per_night   date_id\n",
       "0    41791859              120  28012020\n",
       "1    41791859              120  29012020\n",
       "2    41791859              120  30012020\n",
       "3    41791859              120  31012020\n",
       "4    41791859              120   1022020"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bookings_etl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets merge the availability data the we select (the first 100k records) with the listings available in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that we ensure that we are inserting data in availabilty fact table that has correspondence with the listings that we inserted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're doing this because during the ETL process of our dimensions we are deleting some records that have missing values, for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57566, 5)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bookings_etl = pd.merge(df_listings_facts_sql,df_bookings_etl,how='inner',on='listing_id')[['property_id','date_id_y','host_id','location_id','price_per_night_y']]\n",
    "df_bookings_etl = df_bookings_etl.rename(columns = {'price_per_night_y':'price_per_night'})\n",
    "df_bookings_etl = df_bookings_etl.rename(columns = {'date_id_y':'date_id'})\n",
    "df_bookings_etl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query availability fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>host_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>price_per_night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [property_id, date_id, host_id, location_id, price_per_night]\n",
       "Index: []"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = psycopg2.connect(host = dbconnection.server_host,database = dbconnection.dbname, user = dbconnection.dbusername,password = dbconnection.dbpassword,sslmode=dbconnection.sslmode,gssencmode=dbconnection.gssencmode)\n",
    "df_bookings_sql = query_table(conn, 'booking')\n",
    "conn.close()\n",
    "df_availabity_sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get just the data needed to insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>host_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>price_per_night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28012020</td>\n",
       "      <td>107347</td>\n",
       "      <td>1194</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29012020</td>\n",
       "      <td>107347</td>\n",
       "      <td>1194</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>30012020</td>\n",
       "      <td>107347</td>\n",
       "      <td>1194</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>31012020</td>\n",
       "      <td>107347</td>\n",
       "      <td>1194</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1022020</td>\n",
       "      <td>107347</td>\n",
       "      <td>1194</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57561</th>\n",
       "      <td>112</td>\n",
       "      <td>22012021</td>\n",
       "      <td>7665008</td>\n",
       "      <td>743</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57562</th>\n",
       "      <td>112</td>\n",
       "      <td>23012021</td>\n",
       "      <td>7665008</td>\n",
       "      <td>743</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57563</th>\n",
       "      <td>112</td>\n",
       "      <td>24012021</td>\n",
       "      <td>7665008</td>\n",
       "      <td>743</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57564</th>\n",
       "      <td>112</td>\n",
       "      <td>25012021</td>\n",
       "      <td>7665008</td>\n",
       "      <td>743</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57565</th>\n",
       "      <td>112</td>\n",
       "      <td>26012021</td>\n",
       "      <td>7665008</td>\n",
       "      <td>743</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20483 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       property_id   date_id  host_id  location_id  price_per_night\n",
       "0                1  28012020   107347         1194               50\n",
       "1                1  29012020   107347         1194               50\n",
       "2                1  30012020   107347         1194               50\n",
       "3                1  31012020   107347         1194               50\n",
       "4                1   1022020   107347         1194               50\n",
       "...            ...       ...      ...          ...              ...\n",
       "57561          112  22012021  7665008          743               89\n",
       "57562          112  23012021  7665008          743               89\n",
       "57563          112  24012021  7665008          743               89\n",
       "57564          112  25012021  7665008          743               87\n",
       "57565          112  26012021  7665008          743               87\n",
       "\n",
       "[20483 rows x 5 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bookings_insert = get_data_to_insert(df_bookings_etl,df_bookings_sql,['property_id','date_id'])\n",
    "df_bookings_insert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert availability data into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/50626058/psycopg2-cant-adapt-type-numpy-int64\n",
    "from psycopg2.extensions import register_adapter, AsIs\n",
    "psycopg2.extensions.register_adapter(np.int64, psycopg2._psycopg.AsIs)\n",
    "\n",
    "if len(df_availability_insert) > 0:\n",
    "    table_name = 'booking'\n",
    "    conn = psycopg2.connect(host = dbconnection.server_host,database = dbconnection.dbname, user = dbconnection.dbusername,password = dbconnection.dbpassword,sslmode=dbconnection.sslmode,gssencmode=dbconnection.gssencmode)\n",
    "    success = insert_data(df_bookings_insert,table_name, conn)\n",
    "    conn.close()\n",
    "    if success == True: print('Data inserted successfully')\n",
    "else: print('No data to insert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Critical assessment of the work\n",
    "+ Describe potential issues with the ETL procedure used\n",
    "+ Compare your schema to the one previously defined in phase I\n",
    "+ Discuss the issues for updating the data warehouse with novel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mention that dimensions might have unnecessary rows! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe facts loading:\n",
    "* Merge every mapping\n",
    "* Merge with one fact\n",
    "* Merge Facts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
